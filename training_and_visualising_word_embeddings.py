# -*- coding: utf-8 -*-
"""Training and Visualising Word Embeddings.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yBfakqe8848dqhKAfn9o3qIpDelCcoY

### Loading Data
"""

file = open('Royal_data.txt', 'r')
royal_data = file.readlines()
print(royal_data)
file.close()

"""### Removing '\n' from the end of every sentence and convert the sentence into lowercase   

"""

for i in range(len(royal_data)):
    royal_data[i] = royal_data[i].lower().replace('\n', '')

print(royal_data)

"""### Removing stop words

"""

stopwords = ['the', 'is', 'will', 'be', 'a', 'only', 'can', 'their', 'now', 'and', 'at', 'it']

filtered_data = []
for sent in royal_data:
    temp = []
    for word in sent.split():
        if word not in stopwords:
            temp.append(word)
    filtered_data.append(temp)

print(filtered_data)

"""### Creating bigrams

"""

bigrams = []
for words_list in filtered_data:
    for i in range(len(words_list) - 1):
        for j in range(i+1, len(words_list)):
            bigrams.append([words_list[i], words_list[j]])
            bigrams.append([words_list[j], words_list[i]])


print(bigrams)

"""### Getting a list of unique words"""

all_words = []
for bi in bigrams:
    all_words.extend(bi)

all_words = list(set(all_words))
all_words.sort()

print(all_words)
print("Total number of unique words are:", len(all_words))

"""### Creating dictionary of words"""

words_dict = {}

counter = 0
for word in all_words:
    words_dict[word] = counter
    counter += 1

print(words_dict)

"""### Performing one-hot encoding"""

import numpy as np

onehot_data = np.zeros((len(all_words), len(all_words)))

for i in range(len(all_words)):
    onehot_data[i][i] = 1

onehot_dict = {}
counter = 0
for word in all_words:
    onehot_dict[word] = onehot_data[counter]
    counter += 1

for word in onehot_dict:
    print(word, ":", onehot_dict[word])

onehot_data

X = []
Y = []

for bi in bigrams:
    X.append(onehot_dict[bi[0]])
    Y.append(onehot_dict[bi[1]])

X = np.array(X)
Y = np.array(Y)

len(X), len(Y)

"""### Model"""

from keras.models import Sequential
from keras.layers import Dense

embed_size = 2

model = Sequential([
    Dense(embed_size, activation='linear'),
    Dense(Y.shape[1], activation = 'softmax')
])

model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import Callback

class CustomWeightsCallback(Callback):
    def __init__(self):
        super(CustomWeightsCallback, self).__init__()
        self.weights_history = []
        self.final_df = pd.DataFrame()


    def create_list(self, row):
        return [row[0], row[1]]

    def on_epoch_end(self, epoch, logs=None):
        # Extract weights
        weights = self.model.get_weights()[0]

        self.current_df = pd.DataFrame(weights)

        self.current_df['C'] = self.current_df.apply(self.create_list, axis=1)
        self.appended_weights = self.current_df['C'].transpose()
        self.t_weights = pd.DataFrame([self.appended_weights])
        self.final_df = pd.concat([self.final_df, self.t_weights])

# Callback instance
weights_callback = CustomWeightsCallback()

model.fit(X, Y, epochs = 1700, batch_size = 256, callbacks=[weights_callback], verbose = False)

weight_matrices = weights_callback.final_df
weight_matrices.columns = all_words
weight_matrices.reset_index(drop='index')

import shutil
import os

shutil.rmtree('/content/plots')
os.makedirs('/content/plots')

import matplotlib.pyplot as plt
from tqdm import tqdm
# plt.figure(figsize = (10, 10))
for frame in tqdm(range(len(weight_matrices))):
  word_embeddings = weight_matrices.iloc[frame].to_dict()
  for word in list(words_dict.keys()):
      coord = word_embeddings.get(word)
      plt.scatter(coord[0], coord[1])
      plt.annotate(word, (coord[0], coord[1]))

  plt.savefig(f'plots/img_{frame}.png')
  plt.clf()

import cv2
import numpy as np

image_paths = [f'plots/img_{frame}.png' for frame in range(len(weight_matrices))]  # Example list of image paths

first_image = cv2.imread(image_paths[0])
height, width, _ = first_image.shape

fourcc = cv2.VideoWriter_fourcc(*'MP4V')
video_writer = cv2.VideoWriter('output_video.mp4', fourcc, 15, (width, height))  # Output video file name, codec, FPS, and frame size

for image_path in image_paths:
    image = cv2.imread(image_path)
    video_writer.write(image)

#save the plot video
video_writer.release()

